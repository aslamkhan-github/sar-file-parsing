input {

 file {
     path => '/root/sar_content/Ch/*/sar*'
     start_position  => "beginning"
     sincedb_path  => "/dev/null"
    }
}


filter {

  # drop line with Name starts with Linux
   if [message] =~ '/Linux$/' {
    drop { }
  }

  # drop lines containing Avarage
  if [message] =~ '/^# Average/' {
    drop { }
  }

 #CPU DATA
  csv {
    separator => ","
    columns => ["sar_time","CPU","user","nice","system","iowait","steal","irq","soft","guest","idle"]
   }
 
  grok {
      match => { "message" => "\A(?<sar_time>%{HOUR}:%{MINUTE}:%{SECOND}\s+%{WORD:A-Z})\s+%{NUMBER:CPU:integer}\s+%{NUMBER:user:float}\s+%{NUMBER:nice:float}\s+%{NUMBER:system:float}\s+%{NUMBER:iowait:float}\s+%{NUMBER:steal:float}\s+%{NUMBER:irq:float}\s+%{NUMBER:soft:float}\s+%{NUMBER:guest:float}\s+%{NUMBER:idle:float}" }                              
    }

    mutate {
    convert => ["CPU","integer"]
    remove_field => [ "message" ]
    remove_field => [ "A-Z" ]
   }
   
   mutate {
   rename => { "CPU" => "CPU No." }
   #remove_field => "sar_time"
      #gsub => [
       # "sar_time","[]",""
      #]
   }

   if "_grokparsefailure" in [tags] {
                drop { }
    }      
   
}


output {
  stdout {
     codec => rubydebug
  }
  elasticsearch {
    hosts => [ "localhost:9200" ]
    index => "sar_cpu-%{+YYYY.MM.dd}"
    document_type => "default"
    http_compression => true
  }
}
